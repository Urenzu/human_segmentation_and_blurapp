{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('custom_unet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blur around human:\n",
    "The function preprocesses the image in the correct dimensions that the neural network is compatible with. The model predicts the mask and then resizes the mask for the original image resolution.\n",
    "It inverts the mask capturing the surroundings of the human. Uses OpenCV to apply a blurred effect on the inverted mask area then replicate the mask across three channels to make it compatible with rgb.\n",
    "\n",
    "\"\"\"\n",
    "def predict_segmentation(input_image):\n",
    "    image_np = np.array(input_image)\n",
    "    image_resized = cv2.resize(image_np, (256, 256)) / 255.0\n",
    "    image_expanded = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "    predicted_mask = model.predict(image_expanded)[0]\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    mask_resized = cv2.resize(predicted_mask, (input_image.size[0], input_image.size[1]))\n",
    "    inverted_mask = 1 - mask_resized\n",
    "\n",
    "    blurred_background = cv2.GaussianBlur(image_np, (51, 51), 0)\n",
    "\n",
    "    inverted_mask_3ch = np.stack((inverted_mask,)*3, axis=-1)\n",
    "\n",
    "    segmented_image = np.where(inverted_mask_3ch == 1, blurred_background, image_np)\n",
    "\n",
    "    segmented_pil = Image.fromarray(segmented_image.astype('uint8'), 'RGB')\n",
    "    return segmented_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal gradio code for bringing model to a webapp.\n",
    "demo = gr.Interface(\n",
    "    predict_segmentation,\n",
    "    gr.Image(type=\"pil\"),\n",
    "    \"image\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
